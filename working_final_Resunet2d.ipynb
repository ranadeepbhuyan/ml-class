{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranadeepbhuyan/ml-class/blob/master/working_final_Resunet2d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPmJQMvloL__",
        "outputId": "319ba6c6-d613-46aa-b603-9544d5f06e1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-preprocessing) (1.24.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras-preprocessing) (1.16.0)\n",
            "Installing collected packages: keras-preprocessing\n",
            "Successfully installed keras-preprocessing-1.1.2\n"
          ]
        }
      ],
      "source": [
        "pip install  keras-preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bW6aDqCNoCW"
      },
      "outputs": [],
      "source": [
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDzh3Pshl0Th"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import zipfile\n",
        "import cv2\n",
        "from skimage import io\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "import random\n",
        "import glob\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "from IPython.display import display\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grhWlsxlsfCQ",
        "outputId": "d9b0627f-a98e-4b65-b64b-ae719067e4db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C77UeHqOIzMo"
      },
      "outputs": [],
      "source": [
        "#Required datapaths\n",
        "training_dataPath = r\"/content/drive/MyDrive/training_dataset_nii/3d_to_2d_dataset\"\n",
        "mask_path = r\"/content/drive/MyDrive/training_dataset_nii/3d_to_2d_mask\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CL8Ircz3MtkA"
      },
      "outputs": [],
      "source": [
        "#fatching ids form data path\n",
        "def pathListIntoIds(dirList):\n",
        "    x = []\n",
        "    for i in range(0,len(dirList)):\n",
        "        x.append(dirList[i][dirList[i].rfind('/')+1:])\n",
        "    return x\n",
        "\n",
        "train_data_ids = [f.path for f in os.scandir(training_dataPath)]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_mask_ids = [f.path for f in os.scandir(mask_path)]"
      ],
      "metadata": {
        "id": "2Tf0E4TcT-nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuuTtAZ0MQzU",
        "outputId": "1b31daf5-d959-4c1b-c018-21ca351a6fbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41692"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(train_data_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SThAKp1tbIWO",
        "outputId": "1776dde9-08a7-4199-bfd1-cdb055950d75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41704"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(train_data_mask_ids)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "training_mask_ids = pathListIntoIds(train_data_mask_ids );\n",
        "training_data_ids = pathListIntoIds(train_data_ids);"
      ],
      "metadata": {
        "id": "EJZJPgrQUW4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "L0gYxs_YNiSU",
        "outputId": "16408758-0ece-4749-da23-25a3dcd1d337"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'UCSF-PDGM-0004_nifti-slice000_x.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "training_data_ids.sort()\n",
        "training_data_ids[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Z7aeXSniNol1",
        "outputId": "5ba0fa53-0213-4cf0-933c-86c68a84226e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'UCSF-PDGM-0004_nifti-slice000_x.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "training_mask_ids.sort()\n",
        "training_mask_ids[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67MjFP6Uadem"
      },
      "outputs": [],
      "source": [
        "def remove_unmatch_ids(dataset1,dataset2):\n",
        "  for i in dataset1:\n",
        "    if i not in dataset2:\n",
        "      dataset1.remove(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wA5GCLv3bnVi"
      },
      "outputs": [],
      "source": [
        "remove_unmatch_ids(training_data_ids,training_mask_ids)\n",
        "remove_unmatch_ids(training_mask_ids,training_data_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMCBkpLBbwfO",
        "outputId": "4a36e1f0-7ef1-4b46-f62a-52f1d6969bb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41636"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "len(training_data_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vioPxuQOb4wF",
        "outputId": "cf85bdb3-234b-4709-96ba-102d490132e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41636"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "len(training_mask_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZVZyzubT3xk"
      },
      "outputs": [],
      "source": [
        "result = []\n",
        "for i in training_mask_ids:\n",
        "    if i not in training_data_ids:\n",
        "      result.append(i)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk7AGdjUUTQI",
        "outputId": "5da20522-449f-4821-f24d-13ee6a472001"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_F1zs8hVERk",
        "outputId": "2e921306-923f-43be-ab8b-f0e35393c003"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41636"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len(training_mask_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw0O_USXX4-C",
        "outputId": "8672c437-c5ef-4125-a9c4-d617069782d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41636"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "len(training_data_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4fLcwaaV9CV"
      },
      "outputs": [],
      "source": [
        "def remove_png(dataset):\n",
        "  x = []\n",
        "  for i in range(0,len(dataset)):\n",
        "    y = dataset[i].split('.png')[0]\n",
        "    x.append(y)\n",
        "  return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgtpN5CTWxjx"
      },
      "outputs": [],
      "source": [
        "training_data_ids = remove_png(training_mask_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3sFce3mAXQjX",
        "outputId": "306dd27b-963c-4c7f-92f2-a563b76c6763"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'UCSF-PDGM-0047_nifti-slice160_x'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "training_data_ids[20000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQc4JL_dXciW",
        "outputId": "d1da130d-6544-46b7-8e10-0d6061061585"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41636"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "len(training_data_ids)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training_data_ids2=[]\n",
        "#for i in range(20000,len(training_data_ids)):\n",
        "  #training_data_ids2.append(training_data_ids[i])\n",
        "\n"
      ],
      "metadata": {
        "id": "e0YPxD1X7X3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#len(training_data_ids2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLZMVvsc8HOY",
        "outputId": "f0264624-56f3-4d00-aa5e-6239be65c31c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21636"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooYJu5RB8dAa"
      },
      "outputs": [],
      "source": [
        "#removing the black images form the dataset\n",
        "import cv2\n",
        "final_training_ids = []\n",
        "img_path = r\"/content/drive/MyDrive/training_dataset_nii/3d_to_2d_dataset\"\n",
        "for i in range(0,20000):\n",
        "  training_data_path = os.path.join(img_path, f'{training_data_ids[i]}.png');\n",
        "# Load the image\n",
        "  image = cv2.imread(training_data_path)\n",
        "\n",
        "# Convert the image to grayscale\n",
        "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Calculate the gray level\n",
        "  gray_level = gray_image.max()\n",
        "\n",
        "# append the mask_ids into a new list\n",
        "  if gray_level > 175:\n",
        "    final_training_ids.append(training_data_ids[i])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#contain firts 20000 dataset\n",
        "len(final_training_ids)"
      ],
      "metadata": {
        "id": "zLfe9MYX0VvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b689e2d8-d6a3-42f5-9987-b191b92fe90d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12770"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ids, val_ids = train_test_split(final_training_ids,test_size=0.2)"
      ],
      "metadata": {
        "id": "DwHdLk4zRkAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKszGv_9S52F",
        "outputId": "84f3ae21-b10e-4770-baa3-c4dbacd16a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10216"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvJ5-uI4S9KL",
        "outputId": "43a8e90e-14d8-4bcd-acda-ca44ccf419e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2554"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "MBpGXlECKsAW",
        "outputId": "1b7f96de-15c4-48c1-a3d3-733b9ad05dd8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from PIL import Image\n",
        "#img_path = r\"/content/drive/MyDrive/Colab Notebooks/BRTS/3ddatato2ddataofbrats /traindata2\"\n",
        "for i in range(0,1):\n",
        "  mask_path1 = os.path.join(img_path, f'{final_training_ids[i]}.png');\n",
        "  image_path = mask_path1\n",
        "\n",
        "# Open the image using PIL\n",
        "  image = Image.open(image_path)\n",
        "\n",
        "# Display the image using matplotlib\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')  # Turn off axis ticks and labels\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f7fSQ303m0n"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "  def __init__(self, ids , mask, image_dir = './', batch_size = 16, img_h = 128, img_w = 128, shuffle = True):\n",
        "\n",
        "    self.ids = ids\n",
        "    self.mask = mask\n",
        "    self.image_dir = image_dir\n",
        "    self.batch_size = batch_size\n",
        "    self.img_h = img_h\n",
        "    self.img_w = img_w\n",
        "    self.shuffle = shuffle\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    'Get the number of batches per epoch'\n",
        "\n",
        "    return int(np.floor(len(self.ids)) / self.batch_size)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    'Generate a batch of data'\n",
        "\n",
        "    #generate index of batch_size length\n",
        "    indexes = self.indexes[index* self.batch_size : (index+1) * self.batch_size]\n",
        "\n",
        "    #get the ImageId corresponding to the indexes created above based on batch size\n",
        "    list_ids = [self.ids[i] for i in indexes]\n",
        "\n",
        "    #get the MaskId corresponding to the indexes created above based on batch size\n",
        "    list_mask = [self.mask[i] for i in indexes]\n",
        "\n",
        "\n",
        "    #generate data for the X(features) and y(label)\n",
        "    X, y = self.__data_generation(list_ids, list_mask)\n",
        "\n",
        "    #returning the data\n",
        "    return X, y\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    'Used for updating the indices after each epoch, once at the beginning as well as at the end of each epoch'\n",
        "\n",
        "    #getting the array of indices based on the input dataframe\n",
        "    self.indexes = np.arange(len(self.ids))\n",
        "\n",
        "    #if shuffle is true, shuffle the indices\n",
        "    if self.shuffle:\n",
        "      np.random.shuffle(self.indexes)\n",
        "\n",
        "  def __data_generation(self, list_ids, list_mask):\n",
        "    'generate the data corresponding the indexes in a given batch of images'\n",
        "\n",
        "    # create empty arrays of shape (batch_size,height,width,depth)\n",
        "    #Depth is 3 for input and depth is taken as 1 for output becasue mask consist only of 1 channel.\n",
        "    X = np.empty((self.batch_size, self.img_h, self.img_w, 3))\n",
        "    y = np.empty((self.batch_size, self.img_h, self.img_w, 1))\n",
        "\n",
        "    #iterate through the dataframe rows, whose size is equal to the batch_size\n",
        "    for i in range(len(list_ids)):\n",
        "      #path of the image\n",
        "      img_path = r\"/content/drive/MyDrive/training_dataset_nii/3d_to_2d_dataset\"\n",
        "\n",
        "      #mask path\n",
        "      mask_path = r\"/content/drive/MyDrive/training_dataset_nii/3d_to_2d_mask\"\n",
        "\n",
        "      #reading the original image and the corresponding mask image\n",
        "      data_path = os.path.join(img_path, f'{list_ids[i]}.png');\n",
        "      img = io.imread(data_path)\n",
        "      mask_path1 = os.path.join(mask_path, f'{list_ids[i]}.png');\n",
        "      mask = io.imread(mask_path1)\n",
        "\n",
        "      #resizing and coverting them to array of type float64\n",
        "      img = cv2.resize(img,(self.img_h,self.img_w))\n",
        "      img = np.array(img, dtype = np.float64)\n",
        "\n",
        "      mask = cv2.resize(mask,(self.img_h,self.img_w))\n",
        "      mask = np.array(mask, dtype = np.float64)\n",
        "\n",
        "      #standardising\n",
        "      #img -= img.mean()\n",
        "      #img /= img.std()\n",
        "\n",
        "      #mask -= mask.mean()\n",
        "      #mask /= mask.std()\n",
        "\n",
        "      #Adding image to the empty array\n",
        "      X[i,] = np.expand_dims(img, axis = 2)\n",
        "\n",
        "      #expanding the dimnesion of the image from (256,256) to (256,256,1)\n",
        "      y[i,] = np.expand_dims(mask, axis = 2)\n",
        "\n",
        "    #normalizing y\n",
        "    y = (y > 0).astype(int)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "train_data = DataGenerator(train_ids,train_ids)\n",
        "val_data = DataGenerator(val_ids, val_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwuXLoPfHn0j"
      },
      "outputs": [],
      "source": [
        "# lets create model now\n",
        "def resblock(X, f):\n",
        "    '''\n",
        "    function for creating res block\n",
        "    '''\n",
        "\n",
        "    X_copy = X  #copy of input\n",
        "\n",
        "    # main path\n",
        "    X = Conv2D(f, kernel_size=(1,1), kernel_initializer='he_normal')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    X = Conv2D(f, kernel_size=(3,3), padding='same', kernel_initializer='he_normal')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "\n",
        "    # shortcut path\n",
        "    X_copy = Conv2D(f, kernel_size=(1,1), kernel_initializer='he_normal')(X_copy)\n",
        "    X_copy = BatchNormalization()(X_copy)\n",
        "\n",
        "    # Adding the output from main path and short path together\n",
        "    X = Add()([X, X_copy])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "def upsample_concat(x, skip):\n",
        "    '''\n",
        "    funtion for upsampling image\n",
        "    '''\n",
        "    X = UpSampling2D((2,2))(x)\n",
        "    merge = Concatenate()([X, skip])\n",
        "\n",
        "    return merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HENj2vlaIPBR",
        "outputId": "3a446cc3-0da9-4868-a168-18ffc59a7e4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 128, 128, 16  448         ['input_2[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 128, 128, 16  64         ['conv2d_27[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 128, 128, 16  2320        ['batch_normalization_26[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 128, 128, 16  64         ['conv2d_28[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 64, 64, 16)  0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 64, 64, 32)   544         ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 64, 64, 32)  128         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 64, 64, 32)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 64, 64, 32)   9248        ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 64, 64, 32)   544         ['max_pooling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 64, 64, 32)  128         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 64, 64, 32)  128         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 64, 64, 32)   0           ['batch_normalization_29[0][0]', \n",
            "                                                                  'batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 64, 64, 32)   0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 32)  0           ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 32, 32, 64)   2112        ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 32, 32, 64)  256         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 32, 32, 64)   36928       ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 32, 32, 64)   2112        ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 32, 32, 64)  256         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 32, 32, 64)  256         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 32, 32, 64)   0           ['batch_normalization_32[0][0]', \n",
            "                                                                  'batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 32, 32, 64)   0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 64)  0           ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 16, 16, 128)  8320        ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 16, 16, 128)  512        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 16, 16, 128)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 16, 16, 128)  147584      ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 16, 16, 128)  8320        ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 16, 16, 128)  512        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 16, 16, 128)  512        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 16, 16, 128)  0           ['batch_normalization_35[0][0]', \n",
            "                                                                  'batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 16, 16, 128)  0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 128)   0           ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 8, 8, 256)    33024       ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 8, 8, 256)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 8, 8, 256)    590080      ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 8, 8, 256)    33024       ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 8, 8, 256)    0           ['batch_normalization_38[0][0]', \n",
            "                                                                  'batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 8, 8, 256)    0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 256)  0          ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 16, 16, 384)  0           ['up_sampling2d_4[0][0]',        \n",
            "                                                                  'activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 16, 16, 128)  49280       ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 16, 16, 128)  512        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 16, 16, 128)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 16, 16, 128)  147584      ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 16, 16, 128)  49280       ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 16, 16, 128)  512        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 16, 16, 128)  512        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 16, 16, 128)  0           ['batch_normalization_41[0][0]', \n",
            "                                                                  'batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 16, 16, 128)  0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 128)  0          ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 32, 32, 192)  0           ['up_sampling2d_5[0][0]',        \n",
            "                                                                  'activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 32, 32, 64)   12352       ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 32, 32, 64)  256         ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 32, 32, 64)   36928       ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 32, 32, 64)   12352       ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 32, 32, 64)  256         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 32, 32, 64)  256         ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 32, 32, 64)   0           ['batch_normalization_44[0][0]', \n",
            "                                                                  'batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 32, 32, 64)   0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 64)  0           ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 64, 64, 96)   0           ['up_sampling2d_6[0][0]',        \n",
            "                                                                  'activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 64, 64, 32)   3104        ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 64, 64, 32)  128         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 64, 64, 32)   0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 64, 64, 32)   9248        ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 64, 64, 32)   3104        ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 64, 64, 32)  128         ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 64, 64, 32)  128         ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 64, 64, 32)   0           ['batch_normalization_47[0][0]', \n",
            "                                                                  'batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 64, 64, 32)   0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 32  0          ['activation_29[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate)    (None, 128, 128, 48  0           ['up_sampling2d_7[0][0]',        \n",
            "                                )                                 'batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 128, 128, 16  784         ['concatenate_7[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 128, 128, 16  64         ['conv2d_50[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 128, 128, 16  0           ['batch_normalization_49[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 128, 128, 16  2320        ['activation_30[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 128, 128, 16  784         ['concatenate_7[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 128, 128, 16  64         ['conv2d_51[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 128, 128, 16  64         ['conv2d_52[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 128, 128, 16  0           ['batch_normalization_50[0][0]', \n",
            "                                )                                 'batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 128, 128, 16  0           ['add_15[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 128, 128, 1)  17          ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,210,513\n",
            "Trainable params: 1,206,129\n",
            "Non-trainable params: 4,384\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input_shape = (128,128,3)\n",
        "X_input = Input(input_shape) #iniating tensor of input shape\n",
        "\n",
        "# Stage 1\n",
        "conv_1 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(X_input)\n",
        "conv_1 = BatchNormalization()(conv_1)\n",
        "conv_1 = Conv2D(16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv_1)\n",
        "conv_1 = BatchNormalization()(conv_1)\n",
        "pool_1 = MaxPool2D((2,2))(conv_1)\n",
        "\n",
        "# stage 2\n",
        "conv_2 = resblock(pool_1, 32)\n",
        "pool_2 = MaxPool2D((2,2))(conv_2)\n",
        "\n",
        "# Stage 3\n",
        "conv_3 = resblock(pool_2, 64)\n",
        "pool_3 = MaxPool2D((2,2))(conv_3)\n",
        "\n",
        "# Stage 4\n",
        "conv_4 = resblock(pool_3, 128)\n",
        "pool_4 = MaxPool2D((2,2))(conv_4)\n",
        "\n",
        "# Stage 5 (bottle neck)\n",
        "conv_5 = resblock(pool_4, 256)\n",
        "# Upsample Stage 1\n",
        "up_1 = upsample_concat(conv_5, conv_4)\n",
        "up_1 = resblock(up_1, 128)\n",
        "\n",
        "# Upsample Stage 2\n",
        "up_2 = upsample_concat(up_1, conv_3)\n",
        "up_2 = resblock(up_2, 64)\n",
        "\n",
        "# Upsample Stage 3\n",
        "up_3 = upsample_concat(up_2, conv_2)\n",
        "up_3 = resblock(up_3, 32)\n",
        "\n",
        "# Upsample Stage 4\n",
        "up_4 = upsample_concat(up_3, conv_1)\n",
        "up_4 = resblock(up_4, 16)\n",
        "\n",
        "# final output\n",
        "out = Conv2D(1, (1,1), kernel_initializer='he_normal', padding='same', activation='sigmoid')(up_4)\n",
        "\n",
        "seg_model = Model(X_input, out)\n",
        "seg_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBI_0P9hIda8"
      },
      "outputs": [],
      "source": [
        "# Define a custom loss function for ResUNet model\n",
        "'''\n",
        "actual link for refrence (https://github.com/nabsabraham/focal-tversky-unet/blob/master/losses.py)\n",
        "'''\n",
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "epsilon = 1e-5\n",
        "smooth = 1e-6\n",
        "\n",
        "def tversky(y_true, y_pred):\n",
        "    y_true_pos = K.flatten(y_true)\n",
        "    y_pred_pos = K.flatten(y_pred)\n",
        "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n",
        "    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n",
        "    alpha = 0.7\n",
        "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
        "\n",
        "def focal_tversky(y_true,y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "\n",
        "    pt_1 = tversky(y_true, y_pred)\n",
        "    gamma = 0.75\n",
        "    return K.pow((1-pt_1), gamma)\n",
        "\n",
        "def tversky_loss(y_true, y_pred):\n",
        "    return 1 - tversky(y_true,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i7X1W17KREE",
        "outputId": "7dcaa4fe-0a84-43e1-a353-0beb15c0b405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "adam = tf.keras.optimizers.Adam(lr = 0.001, epsilon = 0.1)\n",
        "seg_model.compile(optimizer = adam,\n",
        "                  loss = focal_tversky,\n",
        "                  metrics = [tversky]\n",
        "                 )\n",
        "#callbacks\n",
        "earlystopping = EarlyStopping(monitor='val_loss',\n",
        "                              mode='min',\n",
        "                              verbose=1,\n",
        "                              patience=20\n",
        "                             )\n",
        "# save the best model with lower validation loss\n",
        "checkpointer = ModelCheckpoint(filepath=\"ResUNet-segModel-weights.hdf5\",\n",
        "                               verbose=1,\n",
        "                               save_best_only=True\n",
        "                              )\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              mode='min',\n",
        "                              verbose=1,\n",
        "                              patience=10,\n",
        "                              min_delta=0.0001,\n",
        "                              factor=0.2\n",
        "                             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "qUrP1LzMKYsn",
        "outputId": "292ed8cb-07a7-4b98-b61a-94d60242525b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.0856 - tversky: 0.9618\n",
            "Epoch 1: val_loss improved from 0.09555 to 0.08335, saving model to ResUNet-segModel-weights.hdf5\n",
            "638/638 [==============================] - 307s 481ms/step - loss: 0.0856 - tversky: 0.9618 - val_loss: 0.0834 - val_tversky: 0.9631 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.0781 - tversky: 0.9655\n",
            "Epoch 2: val_loss did not improve from 0.08335\n",
            "638/638 [==============================] - 298s 466ms/step - loss: 0.0781 - tversky: 0.9655 - val_loss: 0.0886 - val_tversky: 0.9567 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.0754 - tversky: 0.9670\n",
            "Epoch 3: val_loss improved from 0.08335 to 0.06248, saving model to ResUNet-segModel-weights.hdf5\n",
            "638/638 [==============================] - 297s 466ms/step - loss: 0.0754 - tversky: 0.9670 - val_loss: 0.0625 - val_tversky: 0.9747 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "638/638 [==============================] - ETA: 0s - loss: 0.0782 - tversky: 0.9617\n",
            "Epoch 4: val_loss did not improve from 0.06248\n",
            "638/638 [==============================] - 296s 464ms/step - loss: 0.0782 - tversky: 0.9617 - val_loss: 0.0803 - val_tversky: 0.9591 - lr: 0.0010\n",
            "Epoch 5/15\n",
            " 29/638 [>.............................] - ETA: 4:23 - loss: 0.0630 - tversky: 0.9745"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-0fa51ae1e344>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m h = seg_model.fit(train_data, \n\u001b[0m\u001b[1;32m      2\u001b[0m                   \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlystopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "h = seg_model.fit(train_data,\n",
        "                  epochs = 15,\n",
        "                  validation_data = val_data,\n",
        "                  callbacks = [checkpointer, earlystopping, reduce_lr]\n",
        "                 )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(h.h.keys())\n",
        "# summarize history for accuracy\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(h.h['tversky'])\n",
        "plt.plot(h.h['val_tversky'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "\n",
        "# summarize history for loss\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "rw4Tk0PnOcRP",
        "outputId": "bb863e80-d606-4522-a6e4-a1fe542b5e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-257c1e6a91b6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# list all data in history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z3X8JxrTOc92"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOiW/tWZlIfP+SB0NwP9zyZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}